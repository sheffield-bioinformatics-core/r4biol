---
title: "ML applications in breast cancer"
output: html_notebook
---

## Context

Breast cancer is used here an example application of machine learning due to several key factors:

- Large Datasets: There are extensive datasets available for breast cancer research, including gene expression data, clinical information, and patient outcomes. These large datasets provide ample data for training and evaluating machine learning models.

- Complex Relationships: Breast cancer is a complex disease with multiple factors influencing its development and progression. Machine learning algorithms canidentify  patterns and relationships within the data.

- Personalized Treatment: Machine learning can assist in developing personalized treatment plans by identifying patient subgroups with similar characteristics, and predicting their response to different therapies.

The first example will consider the *ER status* of a tumour. ER Status (Estrogen Receptor Status) is a crucial factor in breast cancer. It refers to the presence or absence of estrogen receptors on breast cancer cells.

- ER-Positive: If breast cancer cells have estrogen receptors, they are considered ER-positive. These cells are sensitive to estrogen, and the hormone can stimulate their growth.
- ER-Negative: If breast cancer cells do not have estrogen receptors, they are considered ER-negative. These cells are less likely to be influenced by estrogen.

ER status is traditionally measured using immunohistochemistry (IHC). In IHC, a tissue sample from the breast tumor is treated with antibodies that specifically bind to estrogen receptors. If the antibodies bind to the tumor cells, it indicates the presence of estrogen receptors, making the tumor ER-positive. Importantly, tumours that are ER-positive *generally* have more treatment options and thus patients that are ER-positive have better chances of long-term survival.

**Can we use Machine learning to classify the ER status of a tumour based on omics data?** For this we will use a version of the TCGA dataset that has been processed to include various RNA-seq measurements from a set of genes, along with clinical characteristics of patients.



```{r}
data <- readRDS("brca_ML_example.rds")
data 
```
## Logistic Regression


```{r}
library(tidymodels)

data_er <- filter(data, er_status_by_ihc %in% c("Positive","Negative")) %>% 
  dplyr::rename(ER_Status = er_status_by_ihc) %>% 
  mutate(ER_Status = as.factor(ER_Status))

set.seed(123)  # Set a seed for reproducibility
split <- initial_split(data_er, prop = 0.8)  # Split data into 80% training and 20% testing

train_data <- training(split)
test_data <- testing(split)

# Specify the model
glm_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Fit the model
glm_fit <- fit(glm_spec, ER_Status ~ ESR1, data = train_data)

glm_fit %>% tidy

```

```{r}
# Predict classes on the test set
predictions <- predict(glm_fit, new_data = test_data, type = "class")

# Create a data frame with actual and predicted values
results <- bind_cols(test_data, predictions)
## how many were correct?
dplyr::count(results, ER_Status, .pred_class)
```



```{r}

# Calculate metrics
Metric_Summary <- data.frame(Accuracy = accuracy(results, truth = ER_Status, estimate = .pred_class)$.estimate, 
                  Precision=precision(results, truth = ER_Status, estimate = .pred_class)$.estimate,
                  Recall = recall(results, truth = ER_Status, estimate = .pred_class)$.estimate,
                  F1 = f_meas(results, truth = ER_Status, estimate = .pred_class)$.estimate,
                  Method = "Logistic Regression")

# Visualize predicted classes
ggplot(results, aes(x = ESR1, y = .pred_class,col=ER_Status)) +
  geom_jitter(height=0.1) +
  labs(x = "ESR1 Expression", y = "Predicted Probability of ER-Positive") 
```


```{r}
prob_predictions <- predict(glm_fit, new_data = test_data, type = "prob") 
prob_results <- bind_cols(test_data, prob_predictions) %>% 
  dplyr::select(ER_Status,ESR1,last_col(),last_col(1)) %>% 
  pivot_longer(contains(".pred"), values_to = "Prob",names_to = "Class")

ggplot(prob_results, aes(x = ESR1, y = Prob,col=Class)) + geom_point()

```

## Decision Tree example


```{r}
# Specify the model
dt_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# Fit the model
dt_fit <- fit(dt_spec, ER_Status ~ ESR1, data = train_data)
# Print the model summary
dt_fit
```
```{r}
library(rpart.plot)

# Visualize the tree
rpart.plot(dt_fit$fit)
```


```{r}
ggplot(train_data, aes(x = ER_Status, y = ESR1)) + geom_boxplot() + geom_hline(yintercept = 12)
```

```{r}
library(yardstick)

predictions <- predict(dt_fit, new_data = test_data,type="class")
metrics <- augment(dt_fit, new_data = test_data)



# Calculate metrics
Metric_Summary <- bind_rows(Metric_Summary, data.frame(Accuracy = accuracy(metrics, truth = ER_Status, estimate = .pred_class)$.estimate, 
                  Precision=precision(metrics, truth = ER_Status, estimate = .pred_class)$.estimate,
                  Recall = recall(metrics, truth = ER_Status, estimate = .pred_class)$.estimate,
                  F1 = f_meas(metrics, truth = ER_Status, estimate = .pred_class)$.estimate,
                  Method = "Decision Tree")
)

Metric_Summary
```
## Adding more predictors

```{r}
train_data <- select(train_data, ACTR3B:UBE2T,ER_Status)
test_data <- select(test_data, ACTR3B:UBE2T,ER_Status)

# Fit the model
dt_fit <- fit(dt_spec, ER_Status ~ ., data = train_data)
# Print the model summary
dt_fit
```

```{r}
# Visualize the tree
rpart.plot(dt_fit$fit)
```


```{r}
predictions <- predict(dt_fit, new_data = test_data,type="class")
metrics <- augment(dt_fit, new_data = test_data)

# Calculate metrics
Metric_Summary <- bind_rows(Metric_Summary, data.frame(Accuracy = accuracy(metrics, truth = ER_Status, estimate = .pred_class)$.estimate, 
                  Precision=precision(metrics, truth = ER_Status, estimate = .pred_class)$.estimate,
                  Recall = recall(metrics, truth = ER_Status, estimate = .pred_class)$.estimate,
                  F1 = f_meas(metrics, truth = ER_Status, estimate = .pred_class)$.estimate,
                  Method = "Decision Tree 2")
)
Metric_Summary
```

```{r}
library(vip)
vip(dt_fit)
```
## Trying a random forest
