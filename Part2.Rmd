---
title: "R Introduction for RNA-seq"
author: "Mark Dunning"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output:
  html_document:
    toc: true
    toc_float: yes
    df_print: paged
    css: stylesheets/styles.css
---

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning = FALSE, results = "hide")
```

We have prepared an RNA-seq dataset that uses patients from The Cancer Genome Atlas (TCGA) breast cancer cohort. The purpose of the tutorial is to:-

- show the key stages in performing an RNA-seq analysis from count data
- doing that analysis in a manner that is consistent with the tidyverse framework
- Using RNA-seq to identify biologically-relevant changes in transcription 

This tutorial uses a framework set out in :-
[https://stemangiola.github.io/rpharma2020_tidytranscriptomics/articles/tidytranscriptomics.html](https://stemangiola.github.io/rpharma2020_tidytranscriptomics/articles/tidytranscriptomics.html) as an application of the `tidybulk` package.

The data have to be read into R first. It consists of two files containing the counts and "metadata" about the samples. Both are in tab-delimited files so we can use the `read.table` function from base R. However, since the counts are required to be in a numeric matrix form with `rownames` being gene or feature identifiers we have to manipulate the input data accordingly. Specifically, we need to set the rownames to be the gene names and remove the first column from the input data.

```{r}
meta <- read.table("brca_example_meta.tsv")
raw <- read.table("brca_example.tsv")
counts <- raw[,-1]
rownames(counts) <- raw$ENSEMBL
```

The `SummarizedExperiment` is traditionally the way in which RNA-seq data are stored in R and we will use the temporarily before converting to a format compatible with a "tidyverse" way of thinking. We will briefly examine this format.

```{r message=FALSE}
library(SummarizedExperiment)
brca <- SummarizedExperiment(assays=list(counts=counts),
                     colData=meta,)
brca
```

To save some memory, we can remove the `raw` and `counts` objects as we will no longer need them.

```{r}
rm(raw)
rm(counts)
```

The *raw* counts can be accessed using the `assay` function. Each entry is the number of counts assigned to a particular gene (row) in a given sample (column). The row and column names are the Ensembl gene identifier, and sample name from TCGA.

```{r}
## Use select and slice to print fewer items to the screen
## Feel free to remove these lines if you want to see the full output
library(dplyr)
assay(brca) %>% 
  select(1:4) %>% 
  slice(1:10)
```

If we want to know more information about the biological samples we have to use the `colData` function

```{r}
colData(brca) %>% 
  data.frame %>% 
  dplyr::select(1:4) %>% 
  slice(1:10)
```
The format is not immediately accessible to those familiar with a "`tidyverse`" mindset. Mainly because the data are "wide" and not "long". Consider the code to visualise the distribution of each sample as a boxplot (which is a common QC task)

```{r eval=FALSE}
## Do not try to run this!
ggplot(data, aes(x = ..., y =...)) + geom_boxplot()
```

We might also like to subset our data according to particular sample groupings, or retrieve the data for a given gene and then plot.

## Introduction to tidybulk

The `tidybulk` package solves this issues, and also provides a way of performing other common analysis tasks. Once the `tidybulk` function is applied, the long nature of the data in this format is immediately apparent as we have a huge amount of rows. However, we have all the information we require in the table to permit queries using standard `tidyverse` operations.

```{r}
library(tidybulk)
brca_tidy <- brca %>% tidybulk()
```

```{r eval=FALSE}
## Not evaluated to print excessive printing to screen for the HTML notes.
brca_tidy
```


We can now remove the `brca` object to save memory

```{r}
rm(brca)
```


Say for example we want the counts for a particular gene, and which sample it is most highly-expressed in 

```{r}
brca_tidy %>% 
  filter(.feature == "ENSG00000000003") %>% 
    dplyr::select(counts,patient) %>% 
    arrange(desc(counts)) %>% 
  slice(1:10)
```

Or calculate the average expression in different groups.

```{r results = "asis"}
brca_tidy %>% 
  filter(.feature == "ENSG00000000003") %>% 
    group_by(shortLetterCode) %>% 
    summarise(mean(counts))
```

A basic QC metric is to count the total number of reads for each sample. In a typical bulk RNA-seq study we should be getting 10s of millions of reads - although the total number will vary. Any samples with dramatically lower numbers could be cause for concern.

```{r results = "asis"}
brca_tidy %>% 
  group_by(.sample) %>% 
  summarise(LibrarySize = sum(counts)) %>% 
  mutate(`Library Size - Millions of Reads` = LibrarySize / 1e6)
```
The resulting data can be visualised using a `geom_col` in `ggplot2` for example.

```{r results = "asis"}
library(ggplot2)
brca_tidy %>% 
  group_by(.sample) %>% 
  summarise(LibrarySize = sum(counts)) %>% 
  mutate(`Library Size - Millions of Reads` = LibrarySize / 1e6) %>% 
  ggplot(aes(x=.sample, y = `Library Size - Millions of Reads`)) + geom_col()
```


The above were examples of using the standard `tidyverse` operations. The `tidybulk` package also has functions for implementing the steps in a standard RNA-seq workflow.

## Filtering to expressed features

Genes with extremely low read counts across all samples offer limited evidence of differential expression. These genes can introduce noise into the analysis, potentially affecting the accuracy of statistical methods used downstream. Furthermore, they increase the number of statistical tests performed, leading to a higher risk of false discoveries and reduced power to detect truly differentially expressed genes.


To mitigate these issues, we should filter out genes with insufficient read counts before proceeding with further analysis. This can be achieved using the `keep_abundant` or `identify_abundant` functions within the `tidybulk` package. These functions leverage the `filterByExpr` function from the `edgeR` package (Law et al., 2016), which effectively identifies genes with adequate read counts for reliable differential expression analysis. By default, this filter retains genes with at least 10 counts in a minimum number of samples, typically set to the size of the smallest group in the experimental design.


```{r}
counts_filtered <- brca_tidy %>% keep_abundant(factor_of_interest=er_status_by_ihc)
```

## Scaling counts to normalise

To account for variations in sequencing depth and library composition across samples, we perform count scaling, often referred to as normalization. This process aims to remove systematic biases that do not reflect true biological differences. 

Within the `tidybulk` package, the `scale_abundance` function generates scaled counts. Scaling factors are calculated based on abundant (filtered) transcripts and then applied to all transcripts.

We can select from various normalization methods. In this analysis, we will utilize the default method: trimmed mean of M values (TMM) as implemented in the `edgeR` package (Robinson and Oshlack, 2010).

It's important to note that TMM normalization, like most scaling methods, scales the counts relative to a single reference sample


```{r}
counts_scaled <- counts_filtered %>% scale_abundance()
```

## Dimensionality reduction

Principal Component Analysis (**PCA**) and Multi-Dimensional Scaling (**MDS**) plots are among the most crucial visualizations for analyzing RNA-sequencing data. These techniques reduce the dimensionality of the data, allowing us to identify the primary sources of variation.

PCA, an unsupervised learning method, explores the data without pre-defined groups. In a well-executed experiment, we expect the primary sources of variation to align with the experimental treatments or groups of interest.

Furthermore, PCA is invaluable for quality control and outlier detection.

We can utilize the reduce_dimensions function within the `tidybulk` package to perform these dimensionality reduction analyses. The function reports the proportion of variance explained by the first two components, which by defintion should be higher for PC1.

```{r}
counts_scal_PCA <-
  counts_scaled %>%
  reduce_dimensions(method="PCA")
```

If you print the `counts_scal_PCA` object to screen you will notice that it is still in "long"/"tidy" format, which on this ocassion is not particularly useful for visualisation as many of the variables we need for plotting are repeated many times. To provide a simple summary of PC values for each sample we can use the `pivot_sample` function

```{r results = "asis"}
counts_scal_PCA %>% pivot_sample() %>% 
  dplyr::select(.sample,patient,shortLetterCode,contains("PC"))
```

A basic PCA visualisation will show the values of PC1 and PC2 using a scatter plot with `ggplot2`.

```{r results = "asis"}
counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2)) +
    geom_point() 
```

This clearly shows a separation samples. Our hope is that the separation can be explained by the biological variation rather than technical (e.g batch effects). Having our data in a tidy form allows us to customise the plot.

Although not very helpful in this case, it is often useful to add labels corresponding to sample names

```{r results = "asis"}
library(ggrepel)
counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2,label = patient)) +
    geom_point()  + geom_text_repel()
```

Colouring the points according to variables in the data is often informative. In our case we have several clinial characteristics listed that we could try. The `shortLetterCode` corresponds to whether a particular sample is a primary tumour (TP) or normal tissue (NT) and is a perfect candidate to try.

```{r results = "asis"}
counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2, col = shortLetterCode)) +
    geom_point()
```
The separation on the x-axis, corresponding to the first principal component, is due to the samples being either tumour or normal. This makes perfect sense.

## Exercise

- Use the standard set of tidyverse operations to create a new tidybulk objects corresponding to just the primary tumours.
- Repeat the filtering and normalisation steps, followed by a the PCA
- Which of the clinical variables explains the variation on the PCA?

```{r echo=FALSE}
brca_t <- filter(brca_tidy, shortLetterCode == "TP")

counts_filtered <- brca_t %>% keep_abundant(factor_of_interest=er_status_by_ihc)

counts_scaled <- counts_filtered %>% scale_abundance()

counts_scal_PCA <-
  counts_scaled %>%
  reduce_dimensions(method="PCA")

counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2, col = er_status_by_ihc)) +
    geom_point()

```



We will now concentrate on the analysis of the tumour samples only, but save the whole object for later sections. To reduce the amount of memory usage we will also remove the scaled counts. 

```{r}
brca_t <- filter(brca_tidy, shortLetterCode == "TP")
counts_filtered <- brca_t %>% keep_abundant(factor_of_interest=er_status_by_ihc)

saveRDS(brca_tidy, "data/brca_tidy.RDS")
rm(brca_tidy)
rm(counts_scal_PCA)
rm(counts_scaled)
rm(brca_t)
```



## Gene Annotations


At the moment we don't have particularly meaningful gene names that we can use. We have an Ensembl ID, and have ways to convert between. One of which is using an organism-specific package in Bioconductor. First, we get all the IDs we have.

```{r}
ens_ids <- pull(counts_filtered, .feature) %>% unique
```

The overall strategy is to use `org.Hs.eg.db` to convert between one type of ID (ENSEMBL in our case) to another. We can try the official gene symbol and gene name. For non-human data, equivalent packages are available. e.g. `org.Mm.eg.db` for mouse.

```{r results = "asis"}
library(org.Hs.eg.db)
anno <- AnnotationDbi::select(org.Hs.eg.db,
                              keys = ens_ids,
                              columns = c("SYMBOL","GENENAME"),
                              keytype = "ENSEMBL")
anno %>% slice(1:10)
```



## Testing for differential expression

The `tidybulk` package has simplified workflows to test for differential expression between different conditions. The workflow is not completely automated however because we still need to specify what sample groups to compare and which contrasts to make. This is achieved via the `.formula` argument. The `.contrasts` argument also allows us to explictly define the *direction* of the contrast and which group to use as a baseline; which will affect the sign of the fold-change.



```{r}
counts_de <- counts_filtered %>% 
  filter(er_status_by_ihc %in% c("Positive","Negative")) %>% 
    test_differential_abundance(
      .formula = ~ er_status_by_ihc,
      method = "deseq2",
      .contrasts = list(c("er_status_by_ihc", "Positive","Negative"))
      ,omit_contrast_in_colnames = TRUE
    )
```

The results are still in a *long* format table. Again, this is actually not very helpful and would prefer to have a single row for each gene tested. The function `pivot_transcript` performs the reshaping. We can now add the gene annotation we created earlier, but retain the original Ensembl IDs so we can retrieve count information. The final `arrange` line orders by significance.

```{r results = "asis"}
results_table <- counts_de %>% 
  pivot_transcript() %>% 
  left_join(anno, by=c(".feature"="ENSEMBL")) %>% 
  dplyr::select(-shortLetterCode,-.abundant) %>%
  arrange(padj)
results_table %>% head
```

We can write the results to a spreadsheet for further investigation.

```{r}
write.csv(results_table, "DESeq2_ERpos_vs_EGneg.csv",quote=FALSE,row.names = FALSE)
rm(counts_de)
```


A volcano plot is a common visualisation that shows the degree of significance and magnitude of change. Genes of biological significance are likely to be those with  low p-value and more extreme fold-change.

It would be perfectly possible to make the plot using standard `ggplot2` code. However, the `EnhancedVolcano` package simplifies the process and offers some additional features such as automatically labeling the significant genes.

```{r results = "asis"}
library(EnhancedVolcano)
EnhancedVolcano(results_table, 
                lab = results_table$SYMBOL,
                x = "log2FoldChange",
                y = "padj")
```

Some "sanity checks" are always a good idea too. This can include visualising the scaled counts of the top genes to see if their significance is driven by biological effects, and not technical. First we get the names of the most significant genes. The names have to be in ensembl format as we are going to retrive information on these from the counts data - which has ensembl as an identifier.

```{r}
N <- 10
top_genes <- slice_head(results_table, n=N) %>% pull(.feature)
top_genes
```

We have to repeat the scaling as we removed the object. The annotation information is include to allow more meaningful labels.

```{r}
plot_data <- counts_filtered %>% 
  scale_abundance() %>% 
  filter(.feature %in% top_genes) %>% 
  filter(er_status_by_ihc %in% c("Positive", "Negative")) %>% 
  left_join(anno, by = c(".feature" = "ENSEMBL"))
```

A series of boxplots can now be created, with a facet introduced so that a separate plot is made for each gene. Seeing the gene `ESR1` is particularly encouraging as it is expected to be higher in Estrogen Receptor positive patients.

```{r}
plot_data %>% 
  ggplot(aes(x = er_status_by_ihc, y = counts_scaled,fill=er_status_by_ihc)) + geom_boxplot() + scale_y_log10() + facet_wrap(~SYMBOL)
```

## Extensions

