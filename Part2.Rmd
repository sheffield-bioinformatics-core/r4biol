---
title: "R Introduction for RNA-seq"
author: "Mark Dunning"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
    css: stylesheets/styles.css
---

We have prepared an RNA-seq dataset uses cases that appeared in The Cancer Genome Atlas (TCGA) breast cancer cohort. It consists of X primary tumours and Y normal tissue samples. The purpose of the tutorial is to

- show the key stages in performing an RNA-seq analysis from count data
- doing that analysis in a manner that is consistent with the tidyverse framework

This tutorial uses a framework set out in :-
https://stemangiola.github.io/rpharma2020_tidytranscriptomics/articles/tidytranscriptomics.html

The data have to be read into R first. It consists of two files containing the counts and "metadata" about the samples. Both are in tab-delimited files so we can use the `read.table` function from base R. The counts are required to be in a numeric matrix form with rownames being gene or feature identifiers. We have to manipulate the input data accordingly.

```{r}
meta <- read.table("brca_example_meta.tsv")
raw <- read.table("brca_example.tsv")
counts <- raw[,-1]
rownames(counts) <- raw$ENSEMBL
```

The `SummarizedExperiment` is traditionally the way in which RNA-seq data are stored in R.

```{r message=FALSE}
library(SummarizedExperiment)
brca <- SummarizedExperiment(assays=list(counts=counts),
                     colData=meta)
brca
```

To save some memory, we can remove the `raw` and `counts` objects as we will no longer need them.

```{r}
rm(raw)
rm(counts)
```

The counts can be accessed using the `assay` function. Each entry is the number of counts assigned to a particular gene (row) in a given sample (column). The row and column names are the Ensembl gene identifier, and sample name from TCGA.

```{r}
library(dplyr)
assay(brca) %>% head
```

If we want to know more information about the biological samples we have to use the `colData` function

```{r}
colData(brca) %>% 
  data.frame %>% 
  select(1:4)
```
The format is not immediately accessible to those familiar with a "`tidyverse`" mindset. Mainly because the data are "wide" and not "long". Consider the code to visualise the distribution of each sample as a boxplot (which is a common QC task)

```{r eval=FALSE}
## Do not try to run this!
ggplot(data, aes(x = ..., y =...)) + geom_boxplot()
```

We might also like to subset our data according to particular sample groupings, or retrieve the data for a given gene and then plot.

## Introduction to tidybulk

The `tidybulk` package solves this issues, and also provides a way of performing other common analysis tasks. Once the `tidybulk` function is applied, the long nature of the data in this format is immediately apparent as we have a huge amount of rows. However, we have all the information we require in the table to permit queries using standard `tidyverse` operations.

```{r}
library(tidybulk)
brca_tidy <- brca %>% tidybulk()
brca_tidy
```

```{r}
rm(brca)
```


We just want to see the counts for a particular biological sample

```{r}
brca_tidy %>% 
  filter(patient == "TCGA-BH-A0EE") %>% 
  dplyr::select(.feature,counts)
```

We want the counts for a particular gene, and which sample it is most highly-expressed in 

```{r}
brca_tidy %>% 
  filter(.feature == "ENSG00000000003") %>% 
    dplyr::select(counts,patient) %>% 
    arrange(desc(counts))
```

Or calculate the average expression in different groups.

```{r}
brca_tidy %>% 
  filter(.feature == "ENSG00000000003") %>% 
    group_by(shortLetterCode) %>% 
    summarise(mean(counts))
```

Counting the total number of reads in each sample as a QC metric

```{r}
brca_tidy %>% 
  group_by(.sample) %>% 
  summarise(LibrarySize = sum(counts)) %>% 
  mutate(`Library Size - Millions of Reads` = LibrarySize / 1e6)
```
The above were examples of using the standard `tidyverse` operations. The `tidybulk` package also has functions for implementing the steps in a standard RNA-seq workflow.

## Filtering to expressed features
 

> Genes with very low counts across all libraries provide little evidence for differential expression and they can interfere with some of the statistical approximations that are used later in the pipeline. They also add to the multiple testing burden when estimating false discovery rates, reducing power to detect differentially expressed genes. These genes should be filtered out prior to further analysis. We can perform the filtering using tidybulk keep_abundant or identify_abundant. These functions can use the edgeR filterByExpr function described in (Law et al. 2016) to automatically identify the genes with adequate abundance for differential expression testing. By default, this will keep genes with ~10 counts in a minimum number of samples, the number of the samples in the smallest group. 

```{r}
counts_filtered <- brca_tidy %>% keep_abundant(factor_of_interest=er_status_by_ihc)
counts_filtered
```

## Scaling counts to normalise

> Scaling of counts, normalisation, is performed to eliminate uninteresting differences between samples due to sequencing depth or composition. A more detailed explanation can be found here. In the tidybulk package the function scale_abundance generates scaled counts, with scaling factors calculated on abundant (filtered) transcripts and applied to all transcripts. We can choose from different normalisation methods. Here we will use the default, edgeR’s trimmed mean of M values (TMM), (Robinson and Oshlack 2010). TMM normalisation (and most scaling normalisation methods) scale relative to one sample.

```{r}
counts_scaled <- counts_filtered %>% scale_abundance()
```
## Dimensionality reduction

> By far, one of the most important plots we make when we analyse RNA sequencing data are principal-component analysis (PCA) or multi-dimensional scaling (MDS) plots. We reduce the dimensions of the data to identify the greatest sources of variation in the data. A principal components analysis is an example of an unsupervised analysis, where we don’t need to specify the groups. If your experiment is well controlled and has worked well, what we hope to see is that the greatest sources of variation in the data are the treatments/groups we are interested in. It is also an incredibly useful tool for quality control and checking for outliers. We can use the reduce_dimensions function to calculate the dimensions.

```{r}
counts_scal_PCA <-
  counts_scaled %>%
  reduce_dimensions(method="PCA")
```

```{r}
counts_scal_PCA %>% pivot_sample()
```
A basic PCA visualisation will show the values of PC1 and PC2 using a scatter plot.

```{r}
library(ggplot2)

counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2)) +
    geom_point() 
```
This clearly shows a separation samples. Our hope is that the separation can be explained by the biological variation rather than technical (e.g batch effects). Having our data in a tidy form allows us to customise.

Although not very helpful in this case, it is often useful to add labels corresponding to sample names

```{r}
library(ggrepel)
counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2,label = patient)) +
    geom_point()  + geom_text_repel()
```

Colouring the points according to variables in the data is often informative. In our case we have several clinial characteristics listed that we could try. The `shortLetterCode` corresponds to whether a particular sample is a primary tumour (TP) or normal tissue (NT) is a perfect candidate to try.

```{r}
counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2, col = shortLetterCode)) +
    geom_point()
```
The separation on the x-axis, corresponding to the first principal component, is due to the samples being either tumour or normal. This makes perfect sense

## Exercise

- Use the standard set of tidyverse operations to create a new tidybulk objects corresponding to just the primary tumours.
- Repeat the filtering and normalisation steps, followed by a the PCA
- Which of the clinical variables explains the variation on the PCA?

```{r echo=FALSE}
brca_t <- filter(brca_tidy, shortLetterCode == "TP")

counts_filtered <- brca_t %>% keep_abundant(factor_of_interest=BRCA_Subtype_PAM50)

counts_scaled <- counts_filtered %>% scale_abundance()

counts_scal_PCA <-
  counts_scaled %>%
  reduce_dimensions(method="PCA")

counts_scal_PCA %>%
    pivot_sample() %>%
    ggplot(aes(x=PC1, y=PC2, col = er_status_by_ihc)) +
    geom_point()

```



We will now concentrate on the analysis of the tumour samples only, but save the whole object for later sections. To reduce the amount of memory usage we will also remove the scaled counts. 

```{r}
saveRDS(brca_tidy, "data/brca_tidy.RDS")
rm(brca_tidy)
rm(counts_scal_PCA)
rm(counts_scaled)

```



## Gene Annotations


At the moment we don't have particularly meaningful gene names that we can use. We have an Ensembl ID, and have ways to convert between. One of which is using an organism-specific package in Bioconductor. First, we get all the IDs we have.

```{r}
ens_ids <- pull(counts_filtered, .feature) %>% unique
```

The overall strategy is to use `org.Hs.eg.db` to convert between one type of ID (ENSEMBL in our case) to another. We can try the official gene symbol and gene name. For non-human data, equivalent packages are available. e.g. `org.Mm.eg.db` for mouse.

```{r}
library(org.Hs.eg.db)
anno <- AnnotationDbi::select(org.Hs.eg.db,
                              keys = ens_ids,
                              columns = c("SYMBOL","GENENAME"),
                              keytype = "ENSEMBL")
anno
```



## Testing for differential expression

The `tidybulk` package has simplified workflows to test for differential expression between different conditions. The workflow is not completely automated however because we still need to specify what sample groups to compare and which contrasts to make. This is achieved via the `.formula` argument. The `.contrasts` argument also allows us to explictly define the *direction* of the contrast and which group to use as a baseline; which will affect the sign of the fold-change.



```{r}
counts_de <- counts_filtered %>% 
  filter(er_status_by_ihc %in% c("Positive","Negative")) %>% 
    test_differential_abundance(
      .formula = ~ 0 + er_status_by_ihc,
      method = "deseq2",
      .contrasts = list(c("er_status_by_ihc", "Positive","Negative"))
      ,omit_contrast_in_colnames = TRUE
    )
```

The results are still in a *long* format table. This is actually not very helpful, and would prefer to have a single row for each gene tested. The function `pivot_transcript` performs the reshaping. We can now add the gene annotation we created earlier, but retain the original Ensembl IDs so we can retrieve count information.

The final `arrange` orders by significance.

```{r}
results_table <- counts_de %>% 
  pivot_transcript() %>% 
  left_join(anno, by=c(".feature"="ENSEMBL")) %>% 
  dplyr::select(-shortLetterCode,-.abundant) %>%
  arrange(padj)
results_table
```

A volcano plot is a common visualisation that shows the degree of significance and magnitude of change. It would be perfectly possible to make the plot using standard `ggplot2` code. However, the `EnhancedVolcano` package simplifies the process and offers some additional features

```{r}
library(EnhancedVolcano)
EnhancedVolcano(results_table, 
                lab = results_table$SYMBOL,
                x = "log2FoldChange",
                y = "padj")
```

